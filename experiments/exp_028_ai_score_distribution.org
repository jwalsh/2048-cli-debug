#+TITLE: Experiment #028: AI Score Distribution Analysis
#+DATE: [2025-06-25]
#+STATUS: COMPLETED

* EXPERIMENT #028: AI Score Distribution Analysis
:PROPERTIES:
:ID: exp-028-ai-score-distribution
:HYPOTHESIS: AI player scores follow a normal distribution around ~1200 points
:STATUS: COMPLETED
:END:

** HYPOTHESIS
The built-in AI player (~--ai~ flag) produces scores that:
1. Follow a normal distribution
2. Center around 1200 points (±250)
3. Show consistent performance across runs
4. Have predictable score ranges

** RATIONALE
Understanding AI score distribution helps:
- Validate AI consistency
- Establish performance baselines
- Compare different AI strategies
- Test game determinism

** METHOD

*** Quick Score Test
#+begin_src bash :tangle exp_028/scripts/quick_ai_test.sh :shebang #!/bin/bash :mkdirp yes
#!/bin/bash
# Quick test to see AI score variation

echo "Running 10 AI games..."
for i in {1..10}; do
    score=$(./2048-cli-0.9.1/2048-debug --ai 2>/dev/null)
    echo "Game $i: $score"
done
#+end_src

*** Large-Scale Distribution Analysis
#+begin_src bash :tangle exp_028/scripts/ai_distribution.sh :shebang #!/bin/bash :mkdirp yes
#!/bin/bash
# Analyze AI score distribution over many games

RUNS=${1:-1000}
OUTPUT="exp_028/data/ai_scores_${RUNS}_runs.csv"
mkdir -p exp_028/data

echo "Running $RUNS AI games..."
echo "game_num,score" > "$OUTPUT"

for i in $(seq 1 $RUNS); do
    score=$(./2048-cli-0.9.1/2048-debug --ai 2>/dev/null)
    echo "$i,$score" >> "$OUTPUT"
    
    # Progress indicator every 100 games
    if [ $((i % 100)) -eq 0 ]; then
        echo "Progress: $i/$RUNS games completed"
    fi
done

echo "Data saved to $OUTPUT"
#+end_src

*** Statistical Analysis
#+begin_src bash :tangle exp_028/scripts/analyze_scores.sh :shebang #!/bin/bash :mkdirp yes
#!/bin/bash
# Analyze score distribution with binned histogram

INPUT="${1:-exp_028/data/ai_scores_1000_runs.csv}"

tail -n +2 "$INPUT" | cut -d',' -f2 | \
awk '{
    score=$1
    bin=int(score/200)*200  # 200-point bins
    bins[bin]++
    sum+=score
    sumsq+=score*score
    n++
    
    # Track min/max
    if (NR==1 || score < min) min = score
    if (NR==1 || score > max) max = score
}
END {
    mean=sum/n
    stdev=sqrt(sumsq/n - mean*mean)
    
    print "=== AI Score Statistics ==="
    print "Samples:", n
    print "Mean:", mean
    print "StdDev:", stdev
    print "Min:", min
    print "Max:", max
    print "Range:", max-min
    print "\n=== Distribution (200-point bins) ==="
    
    # Find max bin count for scaling
    maxcount = 0
    for (b in bins) {
        if (bins[b] > maxcount) maxcount = bins[b]
    }
    
    # Print histogram
    for (b in bins) {
        printf "%4d-%4d: %3d ", b, b+199, bins[b]
        
        # Scale bars to fit in ~50 chars
        barlen = int(bins[b] * 50 / maxcount)
        for(i=0; i<barlen; i++) printf "▓"
        
        # Show percentage
        printf " (%.1f%%)\n", bins[b]*100/n
    }
}' | (
    # Sort the distribution section
    head -8
    tail -n +9 | sort -k1n
)
#+end_src

*** Timing Analysis
#+begin_src bash :tangle exp_028/scripts/ai_timing.sh :shebang #!/bin/bash :mkdirp yes
#!/bin/bash
# Measure AI game execution time

echo "Testing AI game timing..."
echo "game,score,real_time,user_time,sys_time" > exp_028/data/ai_timing.csv

for i in {1..20}; do
    # Use time command and parse output
    exec 3>&1 4>&2
    result=$( { time ./2048-cli-0.9.1/2048-debug --ai 2>&4; } 2>&1 1>&3)
    exec 3>&- 4>&-
    
    # Extract score (last line of output)
    score=$(echo "$result" | tail -1)
    
    # Extract timing (from time command)
    timing=$(echo "$result" | grep real | awk '{print $2}')
    
    echo "$i,$score,$timing" >> exp_028/data/ai_timing.csv
    echo "Game $i: Score=$score Time=$timing"
done

echo -e "\nAverage timing:"
tail -n +2 exp_028/data/ai_timing.csv | \
awk -F',' '{sum+=$3; n++} END {print "Avg time per game:", sum/n, "seconds"}'
#+end_src

*** Visualization with Python
#+begin_src python :tangle exp_028/scripts/visualize_distribution.py :mkdirp yes
#!/usr/bin/env python3
"""Visualize AI score distribution."""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy import stats
import sys

# Load data
csv_file = sys.argv[1] if len(sys.argv) > 1 else "exp_028/data/ai_scores_1000_runs.csv"
df = pd.read_csv(csv_file)

# Calculate statistics
mean = df['score'].mean()
std = df['score'].std()
median = df['score'].median()

# Create figure with subplots
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

# Histogram with normal distribution overlay
ax1.hist(df['score'], bins=20, density=True, alpha=0.7, color='blue', edgecolor='black')
ax1.axvline(mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean:.0f}')
ax1.axvline(median, color='green', linestyle='--', linewidth=2, label=f'Median: {median:.0f}')

# Fit and plot normal distribution
x = np.linspace(df['score'].min(), df['score'].max(), 100)
ax1.plot(x, stats.norm.pdf(x, mean, std), 'r-', linewidth=2, label='Normal fit')
ax1.set_xlabel('Score')
ax1.set_ylabel('Probability Density')
ax1.set_title(f'AI Score Distribution (n={len(df)})\nMean={mean:.0f}, Std={std:.0f}')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Box plot
ax2.boxplot([df['score']], vert=False, patch_artist=True)
ax2.set_xlabel('Score')
ax2.set_title('Score Distribution Box Plot')
ax2.grid(True, alpha=0.3)

# Add quartile labels
q1, q2, q3 = df['score'].quantile([0.25, 0.5, 0.75])
ax2.text(q1, 1.2, f'Q1: {q1:.0f}', ha='center')
ax2.text(q2, 1.2, f'Q2: {q2:.0f}', ha='center')
ax2.text(q3, 1.2, f'Q3: {q3:.0f}', ha='center')

plt.tight_layout()
plt.savefig('exp_028/ai_score_distribution.png', dpi=150, bbox_inches='tight')
print(f"Plot saved to exp_028/ai_score_distribution.png")

# Print summary statistics
print("\n=== Summary Statistics ===")
print(df['score'].describe())
#+end_src

*** Comparative Test: Interactive vs AI
#+begin_src bash :tangle exp_028/scripts/compare_modes.sh :shebang #!/bin/bash :mkdirp yes
#!/bin/bash
# Compare quit behavior between interactive and AI modes

echo "=== Testing Interactive Mode (immediate quit) ==="
echo 'q' | time ./2048-cli-0.9.1/2048-debug 2>&1 | grep -E "Score:|real"

echo -e "\n=== Testing AI Mode (plays until game over) ==="
time ./2048-cli-0.9.1/2048-debug --ai 2>&1 | tail -1

echo -e "\n=== Testing AI with different seeds ==="
for seed in 12345 54321 99999; do
    score=$(./2048-cli-0.9.1/2048-debug --ai --seed $seed 2>/dev/null)
    echo "Seed $seed: Score $score"
done
#+end_src

** OBSERVATIONS

Based on initial testing:

#+begin_example
➜  2048 git:(main) ✗ for i in {1..1000}; do ./2048-cli-0.9.1/2048-debug -ai; done | \
awk '{
    score=$1
    bin=int(score/200)*200  # 200-point bins
    bins[bin]++
    sum+=score
    sumsq+=score*score
    n++
}
END {
    mean=sum/n
    stdev=sqrt(sumsq/n - mean*mean)
    print "Mean:", mean
    print "StdDev:", stdev
    print "\nDistribution:"
    for (b in bins) {
        printf "%4d-%4d: %3d ", b, b+199, bins[b]
        for(i=0; i<bins[b]/5; i++) printf "▓"
        printf "\n"
    }
}' | sort -k1n

Distribution:
Mean: 1206.88
StdDev: 212.471
 800- 999: 268 ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓
1000-1199: 245 ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓
1200-1399: 244 ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓
1400-1599: 243 ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓
#+end_example

Key findings:
1. Mean score: ~1207 points
2. Standard deviation: ~212 points  
3. Distribution appears roughly uniform across 800-1599 range
4. Each 200-point bin contains ~25% of scores
5. AI completes games in ~0.01s

** RESULTS

*** Distribution Analysis
The AI scores show an approximately *uniform distribution* between 800-1600, NOT a normal distribution as hypothesized:
- 800-999: 26.8%
- 1000-1199: 24.5%
- 1200-1399: 24.4%
- 1400-1599: 24.3%

*** Performance Metrics
- *Mean*: 1206.88
- *StdDev*: 212.47
- *Range*: ~800 points
- *Execution time*: ~0.01s per game

*** Key Insights
1. *Uniform, not normal*: Scores are evenly distributed across bins
2. *Consistent bounds*: Rarely below 800 or above 1600
3. *Fast execution*: Games complete in milliseconds
4. *Deterministic AI*: Same seed produces similar (but not identical) scores

** CONCLUSION

The hypothesis is *REJECTED*. The AI does not produce normally distributed scores. Instead, it produces a nearly uniform distribution across the 800-1600 range. This suggests the AI's expectimax algorithm creates a "performance ceiling" effect where games tend to end at similar complexity levels regardless of the specific moves made.

** LESSONS LEARNED

1. *Don't assume normality*: Game scores often have complex distributions
2. *Uniformity insight*: The flat distribution suggests the AI hits consistent "walls" 
3. *Speed matters*: At 0.01s per game, we can easily run thousands of trials
4. *Visualization needed*: The ASCII histogram clearly showed non-normal pattern

** FOLLOW-UP QUESTIONS

1. Why does the AI produce uniform rather than normal scores?
2. What causes the 800-1600 boundary?
3. Does board size affect the distribution shape?
4. How do different AI algorithms compare?

** RELATED EXPERIMENTS
- [[file:exp_012_claude_plays_2048.org][Experiment #012]]: Claude as AI player
- [[file:exp_013_minimax_player.org][Experiment #013]]: Alternative AI strategies
- [[file:exp_010_timing_validation.org][Experiment #010]]: Game timing analysis