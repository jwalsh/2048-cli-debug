#+TITLE: Experiment #010: Timing Extrapolation Validation
#+DATE: [2025-06-25]

[[file:exp_010_validation.png]]

* EXPERIMENT #010: Validate Timing Extrapolation with Deep Run
:PROPERTIES:
:ID: exp-010-timing-validation
:HYPOTHESIS: 150 moves will take ~27.75s per run as extrapolated from exp 009
:END:

** HYPOTHESIS
Based on Experiment #009's findings:
1. Game has consistent ~0.16s per move timing
2. 150 moves should take ~27.75s per run (±2s)
3. 50 runs of 150 moves should complete in ~23 minutes
4. Score distribution should be significantly higher than 40-move runs
5. Max tiles should reach 128-256 range consistently

** RATIONALE
We need to validate our timing model before designing larger experiments. If the timing holds linear, we can accurately plan future statistical studies. If not, we need to understand the non-linearity.

** METHOD
*** Parameters Selection
- *Moves*: 150 (3.75x more than exp 009's 40 moves)
- *Runs*: 50 (balance between statistical power and time)
- *Expected duration*: ~23 minutes
- *Move sequence*: "sdsdsdsds..." pattern (alternating down-right)

*** Run Script
#+begin_src bash :tangle exp_010_deep_validation.sh :shebang #!/bin/bash
# Deep validation run: 50 runs with 150 moves each
cd /Users/jasonwalsh/projects/jwalsh/2048/2048-cli-0.9.1

echo "=== Experiment #010: Timing Validation ==="
echo "Hypothesis: 150 moves = ~27.75s per run"
echo "Total expected time: ~23 minutes"
echo ""
echo "Starting at $(date)"
echo "run,score,time_s,max_tile,moves_per_second" > /Users/jasonwalsh/projects/jwalsh/2048/experiments/exp_010_results.csv

# Generate move sequence (150 moves = 75 SD pairs + quit)
MOVES=""
for i in {1..75}; do
    MOVES="${MOVES}sd"
done
MOVES="${MOVES}q"

# Track overall timing
EXPERIMENT_START=$(date +%s.%N)

for run in {1..50}; do
    RUN_START=$(date +%s.%N)
    
    # Execute game
    OUTPUT=$(echo "$MOVES" | ./2048-debug 2>&1)
    
    # Extract score and max tile
    SCORE=$(echo "$OUTPUT" | grep "Score:" | tail -1 | awk '{print $2}')
    MAX_TILE=$(echo "$OUTPUT" | grep -E "^\|" | grep -oE "[0-9]+" | sort -nr | head -1)
    
    # Calculate timing
    RUN_END=$(date +%s.%N)
    TIME_S=$(echo "$RUN_END - $RUN_START" | bc)
    MOVES_PER_SEC=$(echo "scale=3; 150 / $TIME_S" | bc)
    
    # Save result
    echo "$run,$SCORE,$TIME_S,$MAX_TILE,$MOVES_PER_SEC" >> /Users/jasonwalsh/projects/jwalsh/2048/experiments/exp_010_results.csv
    
    # Progress with timing prediction
    if (( run % 5 == 0 )); then
        ELAPSED=$(echo "$(date +%s.%N) - $EXPERIMENT_START" | bc)
        AVG_TIME=$(echo "scale=2; $ELAPSED / $run" | bc)
        REMAINING=$(echo "scale=0; $AVG_TIME * (50 - $run) / 60" | bc)
        echo "Progress: $run/50 runs. Elapsed: ${ELAPSED}s. Est. remaining: ${REMAINING} min"
    fi
done

EXPERIMENT_END=$(date +%s.%N)
TOTAL_TIME=$(echo "$EXPERIMENT_END - $EXPERIMENT_START" | bc)

echo -e "\n=== EXPERIMENT COMPLETE ==="
echo "Total time: $(echo "scale=1; $TOTAL_TIME / 60" | bc) minutes"
echo "Ended at $(date)"
#+end_src

*** Analysis Script
#+begin_src python :tangle exp_010_analysis.py
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os

# Load results
csv_path = os.path.join(os.path.dirname(__file__), 'exp_010_results.csv')
df = pd.read_csv(csv_path)

# Calculate statistics
print("=== TIMING VALIDATION RESULTS ===")
print(f"Total runs: {len(df)}")
print(f"\nTiming Statistics:")
print(f"  Mean time: {df['time_s'].mean():.2f}s (expected: ~27.75s)")
print(f"  Std Dev: {df['time_s'].std():.2f}s")
print(f"  Min: {df['time_s'].min():.1f}s")
print(f"  Max: {df['time_s'].max():.1f}s")
print(f"  Moves/second: {df['moves_per_second'].mean():.3f}")

# Test hypothesis
expected = 27.75
actual = df['time_s'].mean()
error = abs(actual - expected) / expected * 100
print(f"\nHypothesis Test:")
print(f"  Expected: {expected}s")
print(f"  Actual: {actual:.2f}s")
print(f"  Error: {error:.1f}%")
print(f"  Result: {'✅ VALIDATED' if error < 10 else '❌ FAILED'}")

# Score statistics
print(f"\nScore Statistics:")
print(f"  Mean: {df['score'].mean():.1f}")
print(f"  Median: {df['score'].median()}")
print(f"  Max: {df['score'].max()}")

# Max tile distribution
print(f"\nMax Tile Distribution:")
tile_counts = df['max_tile'].value_counts().sort_index()
for tile, count in tile_counts.items():
    print(f"  {tile}: {count} ({count/len(df)*100:.1f}%)")

# Create visualization
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle(f'Experiment #010: Timing Validation ({len(df)} runs, 150 moves each)', fontsize=16)

# 1. Timing distribution with hypothesis line
ax1.hist(df['time_s'], bins=15, edgecolor='black', alpha=0.7, color='steelblue')
ax1.axvline(27.75, color='red', linestyle='--', linewidth=2, label='Hypothesis: 27.75s')
ax1.axvline(df['time_s'].mean(), color='green', linestyle='-', linewidth=2, 
            label=f'Actual: {df["time_s"].mean():.2f}s')
ax1.set_xlabel('Time (seconds)')
ax1.set_ylabel('Frequency')
ax1.set_title('Timing Distribution vs Hypothesis')
ax1.legend()
ax1.grid(True, alpha=0.3)

# 2. Score distribution
ax2.hist(df['score'], bins=20, edgecolor='black', alpha=0.7, color='darkgreen')
ax2.axvline(df['score'].mean(), color='red', linestyle='--', linewidth=2, 
            label=f'Mean: {df["score"].mean():.0f}')
ax2.set_xlabel('Score')
ax2.set_ylabel('Frequency')
ax2.set_title('Score Distribution (150 moves)')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. Timing consistency over runs
ax3.plot(df['run'], df['time_s'], 'o-', alpha=0.6, markersize=4)
ax3.axhline(27.75, color='red', linestyle='--', alpha=0.5, label='Expected')
ax3.fill_between(df['run'], 27.75-2, 27.75+2, alpha=0.2, color='red', label='±2s range')
ax3.set_xlabel('Run Number')
ax3.set_ylabel('Time (seconds)')
ax3.set_title('Timing Consistency')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 4. Max tile distribution
tiles = sorted(df['max_tile'].unique())
counts = [len(df[df['max_tile'] == t]) for t in tiles]
ax4.bar(range(len(tiles)), counts, color='orange', edgecolor='black')
ax4.set_xticks(range(len(tiles)))
ax4.set_xticklabels(tiles)
ax4.set_xlabel('Max Tile')
ax4.set_ylabel('Count')
ax4.set_title('Max Tile Achievement')
ax4.grid(True, alpha=0.3, axis='y')

# Add percentage labels
for i, (tile, count) in enumerate(zip(tiles, counts)):
    ax4.text(i, count + 0.5, f'{count/len(df)*100:.0f}%', ha='center')

plt.tight_layout()
output_path = os.path.join(os.path.dirname(__file__), 'exp_010_validation.png')
plt.savefig(output_path, dpi=150, bbox_inches='tight')
print(f"\nVisualization saved to: exp_010_validation.png")

# Compare with exp 009 (40 moves)
print("\n=== COMPARISON WITH EXP 009 (40 moves) ===")
print("Exp 009: 40 moves, mean time 6.46s = 0.162s/move")
print(f"Exp 010: 150 moves, mean time {df['time_s'].mean():.2f}s = {df['time_s'].mean()/150:.3f}s/move")
print(f"Timing model consistency: {'✅ Linear' if error < 10 else '❌ Non-linear'}")
#+end_src

*** Quick Sanity Check
#+begin_src bash :tangle exp_010_quick_test.sh :shebang #!/bin/bash
# Quick test: 3 runs to verify setup before full experiment
cd /Users/jasonwalsh/projects/jwalsh/2048/2048-cli-0.9.1

echo "=== Quick Sanity Check: 3 runs of 150 moves ==="
MOVES=""
for i in {1..75}; do MOVES="${MOVES}sd"; done
MOVES="${MOVES}q"

for run in {1..3}; do
    echo -n "Run $run: "
    START=$(date +%s.%N)
    echo "$MOVES" | ./2048-debug > /dev/null 2>&1
    END=$(date +%s.%N)
    TIME=$(echo "$END - $START" | bc)
    echo "${TIME}s"
done
#+end_src

** EXPECTED RESULTS
1. Mean time: 27.75s ± 2s
2. Timing consistency: <10% variance
3. Linear scaling confirmed (0.16s/move holds)
4. Score range: 400-1200
5. Max tiles: 50% reach 128, 20% reach 256

** OBSERVATIONS
- Quick test showed ~22-25s per run (lower than hypothesis)
- Full experiment completed in 17.6 minutes (faster than expected 23 min)
- No crashes or timeouts during 50 runs
- Consistent timing with low variance (std dev 1.19s)

** RESULTS
*** Timing Analysis
- *Mean time*: 21.12s (hypothesis: 27.75s)
- *Error*: 23.9% lower than expected
- *Per-move timing*: 0.141s/move (vs 0.162s/move in exp 009)
- *Conclusion*: ❌ Non-linear scaling detected

*** Score Distribution
- Mean: 155.7
- Median: 74.0 (high variance)
- Max achieved: 1344 (one exceptional run)

*** Max Tile Distribution
- ~16~: 38% (most common)
- ~32~: 30%
- ~64~: 10%
- ~128~: 2% (achieved in one run)

** CONCLUSION
*** *Key Finding*: Timing is NOT linear with move count
- 40 moves: ~0.162s/move
- 150 moves: ~0.141s/move
- *13% faster per move* at higher move counts

### *Possible Explanations*:
1. *Game state complexity*: Early moves have more animation/calculation
2. *Startup overhead*: Initial game setup amortized over more moves
3. *Board saturation*: Later moves might process faster with fuller board

### *Implications*:
- Cannot use simple linear extrapolation for timing estimates
- Need to model timing as a function of move count
- Future experiments should account for this non-linearity
- 100 runs of 150 moves would take ~35 minutes, not ~46 as predicted

### *Next Steps*:
1. Test intermediate move counts (60, 90, 120) to map the curve
2. Investigate if board density affects timing
3. Profile the game to understand where time is spent